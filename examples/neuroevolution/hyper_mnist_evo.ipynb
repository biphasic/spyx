{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd3a7575",
   "metadata": {},
   "source": [
    "# Training an SNN using Neuroevolution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf6fa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/legion/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/legion/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail23torchInternalAssertFailEPKcS2_jS2_RKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import spyx\n",
    "import spyx.nn as snn\n",
    "from synecdoche import hyper\n",
    "\n",
    "# JAX imports\n",
    "import os\n",
    "import jax\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".70\"\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# implement our SNN in DeepMind's Haiku\n",
    "import haiku as hk\n",
    "\n",
    "# optimize the parameters using evosax\n",
    "import evosax\n",
    "from evosax.strategies import LM_MA_ES as LMMAES\n",
    "\n",
    "# rendering tools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import graphviz\n",
    "import mediapy as media"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf2a89",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6573ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dl = spyx.data.MNIST_loader(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878677e",
   "metadata": {},
   "source": [
    "## SNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9ee900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_snn(x):\n",
    "    # seqs is [T, F].\n",
    "    core = hk.DeepRNN([\n",
    "        hk.Flatten(),\n",
    "        hk.Linear(128, with_bias=False),\n",
    "        snn.LIF(128, activation=spyx.activation.SuperSpike()),\n",
    "        hk.Linear(128, with_bias=False),\n",
    "        snn.LIF(128, activation=spyx.activation.SuperSpike()),\n",
    "        hk.Linear(10, with_bias=False),\n",
    "        snn.LI(10)\n",
    "    ])\n",
    "    spikes, V = hk.dynamic_unroll(core, x.astype(jnp.float32), core.initial_state(x.shape[0]), time_major=False)\n",
    "    return spikes, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e32e514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "SNN = hk.without_apply_rng(hk.transform(mnist_snn))\n",
    "params = SNN.init(rng=key, x=mnist_dl.train_step().obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df98cd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "HyperNet = hk.without_apply_rng(hk.transform(lambda: hyper.DCT(256, params)()))\n",
    "hypernet_params = HyperNet.init(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63eacdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import tree_util as tree\n",
    "\n",
    "def param_count(hypernetwork_params):\n",
    "    \"\"\" Count the number of learnable params in a network\"\"\"\n",
    "    return sum(tree.tree_leaves(tree.tree_map(jnp.size, hypernetwork_params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "681939a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_count(hypernet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79aa3751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118272"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_count(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f27afe",
   "metadata": {},
   "source": [
    "## Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4503759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolution(SNN, HyperNet, hyper_params, dl, epochs=15, test_every=5, key=0):\n",
    "\n",
    "    rng = jax.random.PRNGKey(key)\n",
    "    param_reshaper = evosax.ParameterReshaper(hyper_params)\n",
    "    \n",
    "\n",
    "    strategy = LMMAES(popsize=64,\n",
    "                num_dims=param_reshaper.total_params,\n",
    "                )\n",
    "    \n",
    "    es_params = strategy.default_params\n",
    "    es_params = es_params.replace(init_min= -1, init_max=1)\n",
    "    # check the initialization here....\n",
    "    state = strategy.initialize(rng)\n",
    "    \n",
    "    @jax.jit\n",
    "    def forward(hyper_params, events):\n",
    "        return SNN.apply(HyperNet.apply(hyper_params), events)\n",
    "        \n",
    "    sim_fn = jax.vmap(forward, (0, None)) #jit this outside the loop...\n",
    "    acc_fn = jax.vmap(spyx.loss.integral_accuracy, (0, None))\n",
    "    loss_fn = jax.vmap(spyx.loss.integral_crossentropy, (0, None))\n",
    "    \n",
    "    @jax.jit\n",
    "    def step(rng, state, events, targets):\n",
    "        rng, rng_ask = jax.random.split(rng, 2)\n",
    "        # ASK\n",
    "        pop, state = strategy.ask(rng_ask, state)\n",
    "        population_params = param_reshaper.reshape(pop.astype(jnp.float32))\n",
    "        # EVAL\n",
    "        spikes, V = sim_fn(population_params, events)\n",
    "        loss = loss_fn(spikes, targets)\n",
    "        # TELL\n",
    "        state = strategy.tell(pop, loss, state)        \n",
    "        \n",
    "        return rng, state, loss\n",
    "    \n",
    "    \n",
    "    for gen in range(epochs):\n",
    "        pbar = tqdm([*range(dl.train_len//dl.batch_size)])\n",
    "        pbar.set_description(\"Epoch #{}\".format(gen))\n",
    "        dl.train_reset()\n",
    "        for _ in pbar:\n",
    "            events, targets = dl.train_step() # non-jittable...\n",
    "\n",
    "            rng, state, loss = step(rng, state, events, targets)\n",
    "            \n",
    "            pbar.set_postfix(Loss=jnp.min(loss))\n",
    "        \n",
    "        elite = param_reshaper.reshape(jnp.array([state.best_member]))\n",
    "        if gen % test_every == test_every-1:\n",
    "            dl.val_reset()\n",
    "            accs = []\n",
    "            losses = []\n",
    "            \n",
    "            pbar = tqdm([*range(dl.val_len//dl.batch_size)])\n",
    "            pbar.set_description(\"Validate\")\n",
    "            for _ in pbar:\n",
    "                events, targets = dl.val_step()\n",
    "                spikes, V = sim_fn(elite, events)\n",
    "                acc, pred = acc_fn(spikes, targets)\n",
    "                loss = loss_fn(spikes, targets)\n",
    "                \n",
    "                accs.append(acc)\n",
    "                losses.append(loss)\n",
    "                \n",
    "                pbar.set_postfix(Loss=np.mean(losses), Accuracy=np.mean(accs))\n",
    "        \n",
    "    return jax.tree_util.tree_map(jnp.squeeze, elite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3634d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterReshaper: 1280 parameters detected for optimization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #0: 100%|███████████████| 656/656 [00:43<00:00, 14.97it/s, Loss=2.3025846]\n",
      "Epoch #1: 100%|███████████████| 656/656 [00:39<00:00, 16.50it/s, Loss=2.3025846]\n",
      "Epoch #2: 100%|███████████████| 656/656 [00:41<00:00, 15.81it/s, Loss=2.3025846]\n",
      "Epoch #3: 100%|███████████████| 656/656 [00:38<00:00, 17.05it/s, Loss=2.3025846]\n",
      "Epoch #4: 100%|███████████████| 656/656 [00:37<00:00, 17.56it/s, Loss=2.3025846]\n",
      "Validate: 100%|█████| 281/281 [00:05<00:00, 48.05it/s, Accuracy=0.101, Loss=2.3]\n",
      "Epoch #5: 100%|███████████████| 656/656 [00:38<00:00, 17.01it/s, Loss=2.3025846]\n",
      "Epoch #6: 100%|███████████████| 656/656 [00:40<00:00, 16.20it/s, Loss=2.3025846]\n",
      "Epoch #7: 100%|███████████████| 656/656 [00:35<00:00, 18.51it/s, Loss=2.3025846]\n",
      "Epoch #8: 100%|███████████████| 656/656 [00:35<00:00, 18.52it/s, Loss=2.3025846]\n",
      "Epoch #9: 100%|███████████████| 656/656 [00:39<00:00, 16.72it/s, Loss=2.3025846]\n",
      "Validate: 100%|█████| 281/281 [00:05<00:00, 48.07it/s, Accuracy=0.101, Loss=2.3]\n",
      "Epoch #10: 100%|██████████████| 656/656 [00:35<00:00, 18.38it/s, Loss=2.3025846]\n",
      "Epoch #11: 100%|██████████████| 656/656 [00:39<00:00, 16.62it/s, Loss=2.3025846]\n",
      "Epoch #12: 100%|██████████████| 656/656 [00:41<00:00, 15.89it/s, Loss=2.3025846]\n",
      "Epoch #13: 100%|██████████████| 656/656 [00:41<00:00, 15.92it/s, Loss=2.3025846]\n",
      "Epoch #14: 100%|██████████████| 656/656 [00:41<00:00, 15.96it/s, Loss=2.3025846]\n",
      "Validate: 100%|█████| 281/281 [00:06<00:00, 41.06it/s, Accuracy=0.101, Loss=2.3]\n"
     ]
    }
   ],
   "source": [
    "elite_params = evolution(SNN, HyperNet, hypernet_params, mnist_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281b68c8",
   "metadata": {},
   "source": [
    "Yikes... Looks like 717,200 parameters is too much for neuroevolution to handle!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12630de8",
   "metadata": {},
   "source": [
    "### Attempt # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9a4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_scnn(x):\n",
    "    # seqs is [T, F].\n",
    "    core = hk.DeepRNN([\n",
    "        hk.MaxPool(3, 3, \"SAME\"),\n",
    "        hk.DepthwiseConv2D(8, 3, with_bias=False),\n",
    "        hk.Flatten(),\n",
    "        hk.Linear(64, with_bias=False),\n",
    "        snn.LIF(64, activation=spyx.activation.SuperSpike()),\n",
    "        hk.Linear(10, with_bias=False),\n",
    "        snn.LI(10)\n",
    "    ])\n",
    "    spikes, V = hk.dynamic_unroll(core, x.astype(jnp.float32), core.initial_state(x.shape[0]), time_major=False)\n",
    "    return spikes, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7df6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "SNN = hk.without_apply_rng(hk.transform(mnist_scnn))\n",
    "params = SNN.init(rng=key, x=mnist_dl.train_step().obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f0d39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(hk.experimental.tabulate(SNN)(mnist_dl.train_step().obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "elite_params = evolution(SNN, params, mnist_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb589eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
